{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lo siento, no estoy seguro de cómo responder a eso. ¿Puedes reformular tu pregunta?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import unicodedata\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Función para predecir la respuesta basada en la entrada del usuario\n",
    "def predict_response(user_input, model_file=r'C:\\Users\\matia\\OneDrive\\Desktop\\Portfolio\\chatbot_model.pkl', training_data_file=r'C:\\Users\\matia\\OneDrive\\Desktop\\Portfolio\\chatbot_data.json'):\n",
    "    # Cargar el modelo entrenado\n",
    "    with open(model_file, 'rb') as model_file:\n",
    "        model_data = pickle.load(model_file)\n",
    "\n",
    "    # Cargar los datos de entrenamiento desde el archivo JSON\n",
    "    with open(training_data_file, 'r', encoding='utf-8') as f:\n",
    "        training_data = json.load(f)    \n",
    "    \n",
    "    # Preprocesar la entrada del usuario utilizando el tokenizador\n",
    "    vectorizer = model_data['vectorizer']\n",
    "    input_texts = model_data['input_texts']\n",
    "    input_to_conv = model_data['input_to_conv']\n",
    "    \n",
    "    user_input_tfidf = vectorizer.transform([user_input])\n",
    "    \n",
    "    # Calcular la similitud de coseno entre la entrada del usuario y los textos entrenados\n",
    "    cosine_similarities = np.dot(user_input_tfidf, model_data['tfidf_matrix'].T).toarray().flatten()\n",
    "    best_match_index = cosine_similarities.argmax()  # Obtener el índice del texto más similar\n",
    "    \n",
    "    # Obtener el umbral de similitud (por ejemplo, 0.3) y verificar si la similitud es baja\n",
    "    threshold = 0.3  # Puedes ajustar este valor según lo que consideres como una respuesta no adecuada\n",
    "    if cosine_similarities[best_match_index] < threshold:\n",
    "        # Elegir una respuesta aleatoria de las respuestas de fallback en los datos de entrenamiento\n",
    "        fallback_responses = training_data.get(\"fallback_responses\", [])\n",
    "        if fallback_responses:\n",
    "            return np.random.choice(fallback_responses)\n",
    "        else:\n",
    "            return \"Lo siento, no estoy seguro de cómo responder a eso. ¿Puedes reformular tu pregunta?\"\n",
    "\n",
    "    # Obtener la respuesta asociada si la similitud es suficiente\n",
    "    response_index = input_to_conv[input_texts[best_match_index]]\n",
    "    response = training_data[\"conversations\"][response_index][\"responses\"]\n",
    "    \n",
    "    # Seleccionar una respuesta aleatoria de las posibles respuestas\n",
    "    return np.random.choice(response)\n",
    "\n",
    "# Función para obtener posibles preguntas de seguimiento (follow-up)\n",
    "def get_follow_up(user_input, model_file='chatbot_model.pkl'):\n",
    "    # Cargar el modelo entrenado\n",
    "    with open(model_file, 'rb') as model_file:\n",
    "        model_data = pickle.load(model_file)\n",
    "    \n",
    "    input_texts = model_data['input_texts']\n",
    "    input_to_conv = model_data['input_to_conv']\n",
    "    follow_up_map = model_data['follow_up_map']\n",
    "    \n",
    "    # Encontrar el índice de la conversación más cercana\n",
    "    user_input_tfidf = model_data['vectorizer'].transform([user_input])\n",
    "    cosine_similarities = np.dot(user_input_tfidf, model_data['tfidf_matrix'].T).toarray().flatten()\n",
    "    best_match_index = cosine_similarities.argmax()\n",
    "    \n",
    "    # Obtener la entrada más cercana y su mapeo de follow-up\n",
    "    best_input = input_texts[best_match_index]\n",
    "    follow_up = follow_up_map.get(best_input, [])\n",
    "    \n",
    "    return follow_up\n",
    "\n",
    "# Función para tokenizar el texto en español\n",
    "def spanish_tokenizer(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = text.lower()\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) \n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "response = predict_response(\"qcy\")\n",
    "        \n",
    "response\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
